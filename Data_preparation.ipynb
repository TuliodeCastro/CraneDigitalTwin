{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d153769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " LOADING CLEANED DATASETS\n",
      "======================================================================\n",
      "\n",
      "âœ… Cleaned datasets loaded:\n",
      "   Z1_CAJICA:   43961 records, 17 columns\n",
      "   Z2_GIRALDA:  44030 records, 13 columns\n",
      "   Z3_OIKOS:    42347 records, 17 columns\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# LOAD CLEANED DATASETS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" LOADING CLEANED DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load cleaned data\n",
    "z1_clean = pd.read_csv('data/cleaned/z1_cajica_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "z2_clean = pd.read_csv('data/cleaned/z2_giralda_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "z3_clean = pd.read_csv('data/cleaned/z3_oikos_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "print(\"\\nâœ… Cleaned datasets loaded:\")\n",
    "print(f\"   Z1_CAJICA:  {len(z1_clean):>6} records, {len(z1_clean.columns):>2} columns\")\n",
    "print(f\"   Z2_GIRALDA: {len(z2_clean):>6} records, {len(z2_clean.columns):>2} columns\")\n",
    "print(f\"   Z3_OIKOS:   {len(z3_clean):>6} records, {len(z3_clean.columns):>2} columns\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ea4568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " STEP 1: SYNCHRONIZING STATIONS\n",
      "======================================================================\n",
      "\n",
      "Original records:\n",
      "  Z1_CAJICA:   43961 records\n",
      "  Z2_GIRALDA:  44030 records\n",
      "  Z3_OIKOS:    42347 records\n",
      "\n",
      "Common timestamps:  40112 records\n",
      "Data loss: 8.90%\n",
      "\n",
      "âœ… Stations synchronized to 40112 records\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# STEP 1: SYNCHRONIZE STATIONS TO COMMON TIMESTAMPS\n",
    "# ============================================================\n",
    "\n",
    "def synchronize_stations(zona1_clean, zona2_clean, zona3_clean):\n",
    "    \"\"\"\n",
    "    Synchronize the 3 stations to common timestamps\n",
    "    Required for barycentric interpolation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STEP 1: SYNCHRONIZING STATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Find common timestamps (intersection)\n",
    "    common_timestamps = zona1_clean.index.intersection(\n",
    "        zona2_clean.index\n",
    "    ).intersection(zona3_clean.index)\n",
    "    \n",
    "    print(f\"\\nOriginal records:\")\n",
    "    print(f\"  Z1_CAJICA:  {len(zona1_clean):>6} records\")\n",
    "    print(f\"  Z2_GIRALDA: {len(zona2_clean):>6} records\")\n",
    "    print(f\"  Z3_OIKOS:   {len(zona3_clean):>6} records\")\n",
    "    print(f\"\\nCommon timestamps: {len(common_timestamps):>6} records\")\n",
    "    \n",
    "    # Calculate data loss\n",
    "    max_records = max(len(zona1_clean), len(zona2_clean), len(zona3_clean))\n",
    "    data_loss = (1 - len(common_timestamps)/max_records) * 100\n",
    "    print(f\"Data loss: {data_loss:.2f}%\")\n",
    "    \n",
    "    # Align dataframes\n",
    "    z1_sync = zona1_clean.loc[common_timestamps].copy()\n",
    "    z2_sync = zona2_clean.loc[common_timestamps].copy()\n",
    "    z3_sync = zona3_clean.loc[common_timestamps].copy()\n",
    "    \n",
    "    print(f\"\\nâœ… Stations synchronized to {len(common_timestamps)} records\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return z1_sync, z2_sync, z3_sync\n",
    "\n",
    "z1_sync, z2_sync, z3_sync = synchronize_stations(z1_clean, z2_clean, z3_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c81fe091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " STEP 2: HANDLING CRITICAL MISSING VALUES\n",
      "======================================================================\n",
      "\n",
      "Timestamps with missing critical data:\n",
      "  Z1_CAJICA:     313 timestamps\n",
      "  Z2_GIRALDA:      0 timestamps\n",
      "  Z3_OIKOS:        7 timestamps\n",
      "  Total:         320 timestamps\n",
      "\n",
      "âš ï¸  Removing 320 timestamps (0.80%)\n",
      "   Reason: Barycentric interpolation requires data from all 3 stations\n",
      "\n",
      "âœ… Final synchronized dataset: 39792 records\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# STEP 2: HANDLE CRITICAL MISSING VALUES\n",
    "# ============================================================\n",
    "\n",
    "def handle_critical_missing_values(z1, z2, z3):\n",
    "    \"\"\"\n",
    "    Remove timestamps where any station has missing critical wind data\n",
    "    Barycentric interpolation requires complete data from all 3 stations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STEP 2: HANDLING CRITICAL MISSING VALUES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    critical_vars = ['Wind Speed (m/sec)', 'Wind Direction (Â°)']\n",
    "    \n",
    "    # Check if any station has missing values at synchronized timestamps\n",
    "    z1_missing = z1[critical_vars].isnull().any(axis=1)\n",
    "    z2_missing = z2[critical_vars].isnull().any(axis=1)\n",
    "    z3_missing = z3[critical_vars].isnull().any(axis=1)\n",
    "    \n",
    "    any_missing = z1_missing | z2_missing | z3_missing\n",
    "    \n",
    "    print(f\"\\nTimestamps with missing critical data:\")\n",
    "    print(f\"  Z1_CAJICA:  {z1_missing.sum():>6} timestamps\")\n",
    "    print(f\"  Z2_GIRALDA: {z2_missing.sum():>6} timestamps\")\n",
    "    print(f\"  Z3_OIKOS:   {z3_missing.sum():>6} timestamps\")\n",
    "    print(f\"  Total:      {any_missing.sum():>6} timestamps\")\n",
    "    \n",
    "    if any_missing.sum() > 0:\n",
    "        removal_pct = (any_missing.sum() / len(z1)) * 100\n",
    "        print(f\"\\nâš ï¸  Removing {any_missing.sum()} timestamps ({removal_pct:.2f}%)\")\n",
    "        print(f\"   Reason: Barycentric interpolation requires data from all 3 stations\")\n",
    "        \n",
    "        # Remove timestamps with any missing critical data\n",
    "        z1_final = z1[~any_missing].copy()\n",
    "        z2_final = z2[~any_missing].copy()\n",
    "        z3_final = z3[~any_missing].copy()\n",
    "        \n",
    "        print(f\"\\nâœ… Final synchronized dataset: {len(z1_final)} records\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… No missing critical values - all {len(z1)} records are usable\")\n",
    "        z1_final, z2_final, z3_final = z1, z2, z3\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return z1_final, z2_final, z3_final\n",
    "\n",
    "z1_final, z2_final, z3_final = handle_critical_missing_values(z1_sync, z2_sync, z3_sync)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd9fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " STEP 3: CREATING COMBINED DATASET\n",
      "======================================================================\n",
      "\n",
      "âœ… Combined dataset created\n",
      "   Records: 39792\n",
      "   Columns: 48\n",
      "   Stations: 3 (Z1_CAJICA, Z2_GIRALDA, Z3_OIKOS)\n",
      "\n",
      "Column structure:\n",
      "  Date column: 1\n",
      "  Z1_CAJICA:   17 variables\n",
      "  Z2_GIRALDA:  13 variables\n",
      "  Z3_OIKOS:    17 variables\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# STEP 3: CREATE COMBINED DATASET\n",
    "# ============================================================\n",
    "\n",
    "def create_combined_dataset(z1, z2, z3):\n",
    "    \"\"\"\n",
    "    Combine the 3 stations into a single wide-format dataset\n",
    "    Each station's variables get a suffix (_z1, _z2, _z3)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STEP 3: CREATING COMBINED DATASET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Reset index to have Date as column\n",
    "    z1_reset = z1.reset_index()\n",
    "    z2_reset = z2.reset_index()\n",
    "    z3_reset = z3.reset_index()\n",
    "    \n",
    "    # Keep only one Date column\n",
    "    date_col = z1_reset[['Date']].copy()\n",
    "    \n",
    "    # Remove Date from individual stations\n",
    "    z1_data = z1_reset.drop('Date', axis=1)\n",
    "    z2_data = z2_reset.drop('Date', axis=1)\n",
    "    z3_data = z3_reset.drop('Date', axis=1)\n",
    "    \n",
    "    # Add suffixes to distinguish stations\n",
    "    z1_data.columns = [f\"{col}_z1\" for col in z1_data.columns]\n",
    "    z2_data.columns = [f\"{col}_z2\" for col in z2_data.columns]\n",
    "    z3_data.columns = [f\"{col}_z3\" for col in z3_data.columns]\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    zones_combined = pd.concat([date_col, z1_data, z2_data, z3_data], axis=1)\n",
    "    \n",
    "    print(f\"\\nâœ… Combined dataset created\")\n",
    "    print(f\"   Records: {len(zones_combined)}\")\n",
    "    print(f\"   Columns: {len(zones_combined.columns)}\")\n",
    "    print(f\"   Stations: 3 (Z1_CAJICA, Z2_GIRALDA, Z3_OIKOS)\")\n",
    "    \n",
    "    # Display column structure\n",
    "    print(f\"\\nColumn structure:\")\n",
    "    z1_cols = [col for col in zones_combined.columns if col.endswith('_z1')]\n",
    "    z2_cols = [col for col in zones_combined.columns if col.endswith('_z2')]\n",
    "    z3_cols = [col for col in zones_combined.columns if col.endswith('_z3')]\n",
    "    \n",
    "    print(f\"  Date column: 1\")\n",
    "    print(f\"  Z1_CAJICA:   {len(z1_cols)} variables\")\n",
    "    print(f\"  Z2_GIRALDA:  {len(z2_cols)} variables\")\n",
    "    print(f\"  Z3_OIKOS:    {len(z3_cols)} variables\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return zones_combined\n",
    "\n",
    "zones_combined = create_combined_dataset(z1_final, z2_final, z3_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "080e4c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " STEP 4: ADDING TEMPORAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "âœ… Temporal features added:\n",
      "   - year, month, day, hour, minute\n",
      "   - day_of_week, day_of_year, week_of_year\n",
      "   - is_weekend, is_daytime\n",
      "   - time_of_day (morning/afternoon/evening/night)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: ADD TEMPORAL FEATURES\n",
    "# ============================================================\n",
    "\n",
    "def add_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Add time-based features useful for analysis and forecasting\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STEP 4: ADDING TEMPORAL FEATURES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure Date is datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Extract temporal components\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day\n",
    "    df['hour'] = df['Date'].dt.hour\n",
    "    df['minute'] = df['Date'].dt.minute\n",
    "    df['day_of_week'] = df['Date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['day_of_year'] = df['Date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['Date'].dt.isocalendar().week\n",
    "    \n",
    "    # Create categorical features\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['is_daytime'] = ((df['hour'] >= 6) & (df['hour'] <= 18)).astype(int)\n",
    "    \n",
    "    # Create time of day categories\n",
    "    def categorize_time_of_day(hour):\n",
    "        if 6 <= hour < 12:\n",
    "            return 'morning'\n",
    "        elif 12 <= hour < 18:\n",
    "            return 'afternoon'\n",
    "        elif 18 <= hour < 22:\n",
    "            return 'evening'\n",
    "        else:\n",
    "            return 'night'\n",
    "    \n",
    "    df['time_of_day'] = df['hour'].apply(categorize_time_of_day)\n",
    "    \n",
    "    print(f\"\\nâœ… Temporal features added:\")\n",
    "    print(f\"   - year, month, day, hour, minute\")\n",
    "    print(f\"   - day_of_week, day_of_year, week_of_year\")\n",
    "    print(f\"   - is_weekend, is_daytime\")\n",
    "    print(f\"   - time_of_day (morning/afternoon/evening/night)\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "zones_combined = add_temporal_features(zones_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "224de854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " STEP 5: ADDING WIND VECTOR COMPONENTS\n",
      "======================================================================\n",
      "   âœ“ Z1: wind_u, wind_v, wind_dir_sin, wind_dir_cos\n",
      "   âœ“ Z2: wind_u, wind_v, wind_dir_sin, wind_dir_cos\n",
      "   âœ“ Z3: wind_u, wind_v, wind_dir_sin, wind_dir_cos\n",
      "\n",
      "âœ… Wind vector components added for all 3 stations\n",
      "   Use U,V components for spatial interpolation\n",
      "   Use sin,cos for circular statistics on direction\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: ADD WIND VECTOR COMPONENTS (CRITICAL FOR INTERPOLATION)\n",
    "# ============================================================\n",
    "\n",
    "def add_wind_vectors(df):\n",
    "    \"\"\"\n",
    "    Convert wind speed and direction to vector components (U, V)\n",
    "    This is ESSENTIAL for barycentric interpolation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STEP 5: ADDING WIND VECTOR COMPONENTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    stations = ['z1', 'z2', 'z3']\n",
    "    \n",
    "    for station in stations:\n",
    "        speed_col = f'Wind Speed (m/sec)_{station}'\n",
    "        dir_col = f'Wind Direction (Â°)_{station}'\n",
    "        \n",
    "        if speed_col in df.columns and dir_col in df.columns:\n",
    "            # Convert direction to radians\n",
    "            dir_rad = np.radians(df[dir_col])\n",
    "            \n",
    "            # Calculate vector components\n",
    "            # U component (east-west): positive towards east\n",
    "            df[f'wind_u_{station}'] = df[speed_col] * np.sin(dir_rad)\n",
    "            \n",
    "            # V component (north-south): positive towards north\n",
    "            df[f'wind_v_{station}'] = df[speed_col] * np.cos(dir_rad)\n",
    "            \n",
    "            # Also encode direction as circular (for analysis/visualization)\n",
    "            df[f'wind_dir_sin_{station}'] = np.sin(dir_rad)\n",
    "            df[f'wind_dir_cos_{station}'] = np.cos(dir_rad)\n",
    "            \n",
    "            print(f\"   âœ“ {station.upper()}: wind_u, wind_v, wind_dir_sin, wind_dir_cos\")\n",
    "    \n",
    "    print(f\"\\nâœ… Wind vector components added for all 3 stations\")\n",
    "    print(f\"   Use U,V components for spatial interpolation\")\n",
    "    print(f\"   Use sin,cos for circular statistics on direction\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "zones_combined = add_wind_vectors(zones_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0307dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " STEP 6: ADDING DERIVED VARIABLES\n",
      "======================================================================\n",
      "   âœ“ Z1: gust_factor, wind_speed_change, wind_speed_change_rate\n",
      "   âœ“ Z2: gust_factor, wind_speed_change, wind_speed_change_rate\n",
      "   âœ“ Z3: gust_factor, wind_speed_change, wind_speed_change_rate\n",
      "\n",
      "âœ… Derived variables added for all 3 stations\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: ADD DERIVED VARIABLES\n",
    "# ============================================================\n",
    "\n",
    "def add_derived_variables(df):\n",
    "    \"\"\"\n",
    "    Add useful derived variables for analysis\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STEP 6: ADDING DERIVED VARIABLES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    stations = ['z1', 'z2', 'z3']\n",
    "    \n",
    "    for station in stations:\n",
    "        speed_col = f'Wind Speed (m/sec)_{station}'\n",
    "        gust_col = f'Wind Gust (m/sec)_{station}'\n",
    "        \n",
    "        if speed_col in df.columns and gust_col in df.columns:\n",
    "            # Gust factor (turbulence indicator)\n",
    "            df[f'gust_factor_{station}'] = df[gust_col] / (df[speed_col] + 0.01)\n",
    "            \n",
    "            # Wind speed change rate (for detecting fronts)\n",
    "            df[f'wind_speed_change_{station}'] = df[speed_col].diff()\n",
    "            df[f'wind_speed_change_rate_{station}'] = df[f'wind_speed_change_{station}'] / 5  # per minute\n",
    "            \n",
    "            print(f\"   âœ“ {station.upper()}: gust_factor, wind_speed_change, wind_speed_change_rate\")\n",
    "    \n",
    "    print(f\"\\nâœ… Derived variables added for all 3 stations\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "zones_combined = add_derived_variables(zones_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "613c7fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Dataset Dimensions:\n",
      "   Records:    39,792\n",
      "   Columns:        80\n",
      "\n",
      "ðŸ“… Time Coverage:\n",
      "   Start:    2025-06-04 00:00:00-05:00\n",
      "   End:      2025-11-04 23:55:00-05:00\n",
      "   Duration: 153 days\n",
      "\n",
      "ðŸŒ¡ï¸ Variable Categories:\n",
      "   Original meteorological:   39 variables\n",
      "   Wind vector components:    12 variables\n",
      "   Derived variables:          9 variables\n",
      "   Temporal features:         11 variables\n",
      "   Quality flags:             20 variables\n",
      "   Date column:                1 column\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   TOTAL:                     80 columns\n",
      "\n",
      "âœ… Missing Values Check:\n",
      "   Total missing values: 6\n",
      "wind_speed_change_z1         1\n",
      "wind_speed_change_rate_z1    1\n",
      "wind_speed_change_z2         1\n",
      "wind_speed_change_rate_z2    1\n",
      "wind_speed_change_z3         1\n",
      "wind_speed_change_rate_z3    1\n",
      "dtype: int64\n",
      "\n",
      "ðŸ’¾ Ready for EDA and Spatial Interpolation!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# STEP 7: FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "def display_final_summary(df):\n",
    "    \"\"\"\n",
    "    Display comprehensive summary of the prepared dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" FINAL DATASET SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Dataset Dimensions:\")\n",
    "    print(f\"   Records:  {len(df):>8,}\")\n",
    "    print(f\"   Columns:  {len(df.columns):>8}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“… Time Coverage:\")\n",
    "    print(f\"   Start:    {df['Date'].min()}\")\n",
    "    print(f\"   End:      {df['Date'].max()}\")\n",
    "    print(f\"   Duration: {(df['Date'].max() - df['Date'].min()).days} days\")\n",
    "    \n",
    "    print(f\"\\nðŸŒ¡ï¸ Variable Categories:\")\n",
    "    \n",
    "    # Count by category\n",
    "    original_vars = len([col for col in df.columns if any(col.endswith(f'_{s}') for s in ['z1','z2','z3']) \n",
    "                        and not any(x in col for x in ['wind_u', 'wind_v', 'wind_dir_sin', 'wind_dir_cos', \n",
    "                                                        'gust_factor', 'wind_speed_change', '_is_missing'])])\n",
    "    vector_vars = len([col for col in df.columns if 'wind_u' in col or 'wind_v' in col \n",
    "                       or 'wind_dir_sin' in col or 'wind_dir_cos' in col])\n",
    "    derived_vars = len([col for col in df.columns if 'gust_factor' in col or 'wind_speed_change' in col])\n",
    "    temporal_vars = len([col for col in df.columns if col in ['year', 'month', 'day', 'hour', 'minute', \n",
    "                                                                'day_of_week', 'day_of_year', 'week_of_year',\n",
    "                                                                'is_weekend', 'is_daytime', 'time_of_day']])\n",
    "    flag_vars = len([col for col in df.columns if '_is_missing' in col or 'warning' in col or 'critical' in col])\n",
    "    \n",
    "    print(f\"   Original meteorological:  {original_vars:>3} variables\")\n",
    "    print(f\"   Wind vector components:   {vector_vars:>3} variables\")\n",
    "    print(f\"   Derived variables:        {derived_vars:>3} variables\")\n",
    "    print(f\"   Temporal features:        {temporal_vars:>3} variables\")\n",
    "    print(f\"   Quality flags:            {flag_vars:>3} variables\")\n",
    "    print(f\"   Date column:              {1:>3} column\")\n",
    "    print(f\"   {'â”€'*35}\")\n",
    "    print(f\"   TOTAL:                    {len(df.columns):>3} columns\")\n",
    "    \n",
    "    print(f\"\\nâœ… Missing Values Check:\")\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    if total_missing == 0:\n",
    "        print(f\"   No missing values! âœ“\")\n",
    "    else:\n",
    "        print(f\"   Total missing values: {total_missing}\")\n",
    "        missing_cols = df.isnull().sum()\n",
    "        print(missing_cols[missing_cols > 0])\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ Ready for EDA and Spatial Interpolation!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "display_final_summary(zones_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "702236a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " SAVING PREPARED DATASET\n",
      "======================================================================\n",
      "\n",
      "âœ… Prepared dataset saved:\n",
      "   - data/prepared/zones_combined_prepared.csv\n",
      "   - 39,792 records\n",
      "   - 80 columns\n",
      "\n",
      "âœ… Dataset ready for EDA in variable: zones_combined_cleaned\n",
      "======================================================================\n",
      "\n",
      "First 5 rows preview:\n",
      "                       Date       Simple Date_z1  Outdoor Temperature (Â°C)_z1  \\\n",
      "0 2025-06-04 00:00:00-05:00  2025-06-04 00:00:00                         13.2   \n",
      "1 2025-06-04 00:05:00-05:00  2025-06-04 00:05:00                         13.2   \n",
      "2 2025-06-04 00:10:00-05:00  2025-06-04 00:10:00                         13.0   \n",
      "3 2025-06-04 00:15:00-05:00  2025-06-04 00:15:00                         12.9   \n",
      "4 2025-06-04 00:20:00-05:00  2025-06-04 00:20:00                         12.8   \n",
      "\n",
      "   Wind Speed (m/sec)_z1  Wind Gust (m/sec)_z1  Max Daily Gust (m/sec)_z1  \\\n",
      "0                    0.5                   1.0                        9.7   \n",
      "1                    0.1                   0.5                        1.0   \n",
      "2                    0.4                   0.5                        1.0   \n",
      "3                    0.0                   0.0                        1.5   \n",
      "4                    0.0                   0.0                        1.5   \n",
      "\n",
      "   Wind Direction (Â°)_z1  Humidity (%)_z1  Solar Radiation (W/m^2)_z1  \\\n",
      "0                  173.0             85.0                         0.0   \n",
      "1                  174.0             85.0                         0.0   \n",
      "2                  183.0             86.0                         0.0   \n",
      "3                  182.0             86.0                         0.0   \n",
      "4                  181.0             86.0                         0.0   \n",
      "\n",
      "   Absolute Pressure (mmHg)_z1  ...  wind_dir_cos_z3  gust_factor_z1  \\\n",
      "0                        565.6  ...        -0.999848        1.960784   \n",
      "1                        565.6  ...        -0.998630        4.545455   \n",
      "2                        565.6  ...        -0.996195        1.219512   \n",
      "3                        565.6  ...        -0.996195        0.000000   \n",
      "4                        565.6  ...        -0.999848        0.000000   \n",
      "\n",
      "   wind_speed_change_z1  wind_speed_change_rate_z1  gust_factor_z2  \\\n",
      "0                   NaN                        NaN        0.000000   \n",
      "1                  -0.4                      -0.08        0.000000   \n",
      "2                   0.3                       0.06        0.000000   \n",
      "3                  -0.4                      -0.08        0.000000   \n",
      "4                   0.0                       0.00        2.439024   \n",
      "\n",
      "   wind_speed_change_z2  wind_speed_change_rate_z2  gust_factor_z3  \\\n",
      "0                   NaN                        NaN        0.000000   \n",
      "1                   0.0                       0.00        0.000000   \n",
      "2                   0.0                       0.00        0.000000   \n",
      "3                   0.0                       0.00        0.000000   \n",
      "4                   0.4                       0.08        0.980392   \n",
      "\n",
      "  wind_speed_change_z3  wind_speed_change_rate_z3  \n",
      "0                  NaN                        NaN  \n",
      "1                  0.0                        0.0  \n",
      "2                  0.0                        0.0  \n",
      "3                  0.0                        0.0  \n",
      "4                  0.5                        0.1  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# STEP 8: SAVE PREPARED DATASET\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" SAVING PREPARED DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save the final prepared dataset\n",
    "zones_combined.to_csv('data/prepared/zones_combined_prepared.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… Prepared dataset saved:\")\n",
    "print(\"   - data/prepared/zones_combined_prepared.csv\")\n",
    "print(f\"   - {len(zones_combined):,} records\")\n",
    "print(f\"   - {len(zones_combined.columns)} columns\")\n",
    "\n",
    "# Also assign to zones_combined_cleaned for consistency with your naming\n",
    "zones_combined_cleaned = zones_combined.copy()\n",
    "\n",
    "print(\"\\nâœ… Dataset ready for EDA in variable: zones_combined_cleaned\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows preview:\")\n",
    "print(zones_combined_cleaned.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
